{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pydot as pyd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "\n",
    "# GPUid to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\";\n",
    "\n",
    "# Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceaa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert initial parameters\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 64\n",
    "n_classes = 3\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(brightness_range = [0.5, 1.25],\n",
    "                                   samplewise_center = True,\n",
    "                                   rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True,\n",
    "                                  rescale = 1./255)\n",
    "\n",
    "train = train_datagen.flow_from_directory('/local/data1/elech646/Tumor_grade_classification/dataset224_t1_sagittal/train', \n",
    "                                          classes = ['G2','G3','G4'], color_mode = 'rgb', \n",
    "                                          class_mode = 'categorical', \n",
    "                                          target_size = (img_height, img_width), \n",
    "                                          batch_size = batch_size, seed = 123)\n",
    "validation = test_datagen.flow_from_directory('/local/data1/elech646/Tumor_grade_classification/dataset224_t1_sagittal/val', \n",
    "                                              classes = ['G2','G3','G4'], color_mode = 'rgb',\n",
    "                                              class_mode = 'categorical', \n",
    "                                              target_size = (img_height, img_width), \n",
    "                                              batch_size = batch_size, seed = 123)\n",
    "test = test_datagen.flow_from_directory('/local/data1/elech646/Tumor_grade_classification/dataset224_t1_sagittal/test', \n",
    "                                        classes = ['G2','G3','G4'], color_mode = 'rgb',\n",
    "                                        shuffle = False, class_mode = 'categorical', \n",
    "                                        target_size = (img_height, img_width), \n",
    "                                        batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b22829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', \n",
    "                                                  classes = np.unique(train.classes), \n",
    "                                                  y = train.classes)\n",
    "\n",
    "# Convert to dictionary\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = next(iter(train))\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train.min())\n",
    "\n",
    "# Plot images for sanity checking\n",
    "def plot_images(images):\n",
    "    fig, axes = plt.subplots(1, 5, figsize = (20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in enumerate(axes):\n",
    "        ax.imshow(images[img,:,:], cmap = 'gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_images(x_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "vgg_19 = VGG19(input_shape = (224, 224, 3), weights = 'imagenet', include_top = False)\n",
    "\n",
    "freeze_until_layer = 100\n",
    "\n",
    "# Freeze all layers before the `freeze_until_layer` layer\n",
    "for layer in vgg_19.layers[:freeze_until_layer]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = vgg_19.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(60, activation = 'relu')(x) \n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(30, activation = 'relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "predictions = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = vgg_19.input, outputs = predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "checkpoint_path = '/local/data1/elech646/code/train_logs/vgg19_transfer_t1_sagittal.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                monitor = 'val_accuracy',\n",
    "                                                mode = 'max',\n",
    "                                                verbose = 1,\n",
    "                                                save_best_only = True)\n",
    "\n",
    "# Save log for history\n",
    "# append: True: append if file exists (useful for continuing training)\n",
    "#         False: overwrite existing file\n",
    "csv_logger = CSVLogger('/local/data1/elech646/code/train_logs/vgg19_transfer_history_t1_sagittal.log', \n",
    "                       separator = ',', append = True)\n",
    "\n",
    "# Reduce learning rate if val_accuracy is not improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.1,\n",
    "                              patience = 5, min_lr = 0.000001)\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy', verbose = 1, \n",
    "                   patience = 15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(Adam(lr = 1e-5),  \n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])   \n",
    "\n",
    "epochs = 45 \n",
    "start = timer()\n",
    "\n",
    "history = model.fit(train, steps_per_epoch = len(train.labels) // batch_size, verbose = 1,\n",
    "                    epochs = epochs, validation_data = validation,\n",
    "                    validation_steps = len(validation.labels) // batch_size,\n",
    "                    class_weight = class_weights,\n",
    "                    callbacks = [es, reduce_lr, checkpoint, csv_logger])\n",
    "\n",
    "end = timer()\n",
    "print(\"Training took: %.2f s\\n\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"vgg19_transfer_t1_sagittal.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"vgg19_transfer_t1_sagittal.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f845b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('vgg19_transfer_t1_sagittal.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"vgg19_transfer_t1_sagittal.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a014c1",
   "metadata": {},
   "source": [
    "1st training:  \n",
    "\n",
    "Setup: `x = vgg_19.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(60, activation = 'relu')(x) \n",
    "        x = Dropout(0.35)(x)\n",
    "        x = Dense(30, activation = 'relu')(x)\n",
    "        predictions = Dense(n_classes, activation = 'softmax')(x)`\n",
    "       \n",
    "batch size = 64\n",
    "\n",
    "number of epochs = 45\n",
    "\n",
    "learning rate = 1e-5 with `ReduceLROnPlateau` + `EarlyStopping`\n",
    "\n",
    "training time: 307.69 s $\\approx 5$ min\n",
    "\n",
    "test accuracy: 0.8021 JESUS CHRIST (slightly overfit tho)\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "2nd training:\n",
    "\n",
    "Setup: `x = vgg_19.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(60, activation = 'relu')(x) \n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Dense(30, activation = 'relu')(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        predictions = Dense(n_classes, activation = 'softmax')(x)`\n",
    "        \n",
    "batch size = 64\n",
    "\n",
    "number of epochs = 45\n",
    "\n",
    "learning rate = 1e-5 with `ReduceLROnPlateau` + `EarlyStopping`\n",
    "\n",
    "training time: 490.22 s $\\approx 8$ min\n",
    "\n",
    "test accuracy: 0.7552 (less overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test loss + accuracy\n",
    "score = model.evaluate(test, steps = len(test.labels) // batch_size, verbose = 0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "n_epochs = range(len(acc))\n",
    "\n",
    "# for fancy LaTeX style plots\n",
    "from matplotlib import rc\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex = True)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(n_epochs, acc, label = 'Training accuracy')\n",
    "plt.plot(n_epochs, val_acc, label = 'Validation accuracy')\n",
    "plt.title('VGG-19: T1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "#plt.savefig('VGG19_t1_sagittal_acc.png', dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(n_epochs, loss, label = 'Training loss')\n",
    "plt.plot(n_epochs, val_loss, label = 'Validation loss')\n",
    "plt.title('VGG-19: T1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc = 'best')\n",
    "#plt.savefig('VGG19_t1_sagittal_loss.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b781a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rounded predictions\n",
    "y_pred = np.argmax(model.predict(test), axis = 1) \n",
    "y_score = model.predict(test)\n",
    "\n",
    "# Get true labels\n",
    "y_true = test.classes\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "ax = sns.heatmap(cm, annot = True, cmap = 'PuBu')\n",
    "ax.set_xlabel('\\nPredicted values')\n",
    "ax.set_ylabel('Actual values ');\n",
    "# list must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Grade 2','Grade 3', 'Grade 4'])\n",
    "ax.yaxis.set_ticklabels(['Grade 2','Grade 3', 'Grade 4'])\n",
    "plt.title('VGG-19: T1 \\n accuracy = 77.86\\%')\n",
    "#plt.savefig('VGG19_CM_t1_sagittal.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print AUC + weighted AUC score\n",
    "weighted_auc = roc_auc_score(y_true, y_score, multi_class = 'ovr', average = 'weighted')\n",
    "auc_score = roc_auc_score(y_true, y_score, multi_class = 'ovr')\n",
    "print(f'AUC score: {auc_score:.4f}')\n",
    "print(f'Weighted AUC score: {weighted_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87536763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 3\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true, y_score[:, i], pos_label = i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this point\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw = 2\n",
    "\n",
    "colors = cycle([\"orange\", \"#9A0EEA\", \"#06C2AC\"])\n",
    "plt.plot([0, 1], [0, 1], \"--\", lw = lw, color = \"#808080\")\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color = color, lw = lw,\n",
    "             label = \"G{0} (AUC = {1:0.2f})\".format(i+2, roc_auc[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multi-class ROC: VGG-19 on T1\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "#plt.savefig('Multi-class ROC: VGG-19 on T1', dpi = 300); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58accc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Save the classification report\n",
    "#clsf_report = pd.DataFrame(classification_report(y_true = y_true, y_pred = y_pred, output_dict = True)).transpose()\n",
    "#clsf_report.to_csv('Classification Report - VGG-19 on t1 sagittal.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
