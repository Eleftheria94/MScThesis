{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pydot as pyd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "\n",
    "# GPUid to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\";\n",
    "\n",
    "# Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceaa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert initial parameters\n",
    "batch_size = 64\n",
    "img_height, img_width = 224, 224\n",
    "n_classes = 3\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(horizontal_flip = True, \n",
    "                                   vertical_flip = True,\n",
    "                                   brightness_range = [0.5, 1.5],\n",
    "                                   samplewise_center = True,\n",
    "                                   rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale = 1./255)\n",
    "\n",
    "train = train_datagen.flow_from_directory('/local/data1/elech646/Tumor_grade_classification/dataset224_t1_sagittal/train', \n",
    "                                          classes = ['G2','G3','G4'], color_mode = 'rgb', \n",
    "                                          class_mode = 'categorical', \n",
    "                                          target_size = (img_height, img_width), \n",
    "                                          batch_size = batch_size, seed = 123)\n",
    "validation = test_datagen.flow_from_directory('/local/data1/elech646/Tumor_grade_classification/dataset224_t1_sagittal/val', \n",
    "                                              classes = ['G2','G3','G4'], color_mode = 'rgb',\n",
    "                                              class_mode = 'categorical', \n",
    "                                              target_size = (img_height, img_width), \n",
    "                                              batch_size = batch_size, seed = 123)\n",
    "test = test_datagen.flow_from_directory('/local/data1/elech646/Tumor_grade_classification/dataset224_t1_sagittal/test', \n",
    "                                        classes = ['G2','G3','G4'], color_mode = 'rgb',\n",
    "                                        shuffle = False, class_mode = 'categorical', \n",
    "                                        target_size = (img_height, img_width), \n",
    "                                        batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f120f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', \n",
    "                                                  classes = np.unique(train.classes), \n",
    "                                                  y = train.classes)\n",
    "\n",
    "# Convert to dictionary\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = next(iter(train))\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train.min())\n",
    "\n",
    "# Plot images for sanity checking\n",
    "def plot_images(images):\n",
    "    fig, axes = plt.subplots(1, 5, figsize = (20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in enumerate(axes):\n",
    "        ax.imshow(images[img,:,:], cmap = 'gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_images(x_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "resnet_50 = ResNet50(input_shape = (224, 224, 3), weights = 'imagenet', include_top = False)\n",
    "\n",
    "freeze_until_layer = 70\n",
    "\n",
    "# Freeze all layers before the `freeze_until_layer` layer\n",
    "for layer in resnet_50.layers[:-freeze_until_layer]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = resnet_50.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(20, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(n_classes, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = resnet_50.input, outputs = predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d62e83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "checkpoint_path = '/local/data1/elech646/code/train_logs/resnet50_transfer_t1_sagittal.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                monitor = 'val_accuracy',\n",
    "                                                mode = 'max',\n",
    "                                                verbose = 1,\n",
    "                                                save_best_only = True)\n",
    "\n",
    "# Save log for history\n",
    "# append: True: append if file exists (useful for continuing training)\n",
    "#         False: overwrite existing file\n",
    "csv_logger = CSVLogger('/local/data1/elech646/code/train_logs/resnet50_transfer_history_t1_sagittal.log', \n",
    "                       separator = ',', append = True)\n",
    "\n",
    "# Reduce learning rate if val_accuracy is not improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.1,\n",
    "                              patience = 5, min_lr = 0.000001)\n",
    "es = EarlyStopping(monitor = 'val_accuracy', verbose = 1, \n",
    "                   patience = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(Adam(lr = 1e-5),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "epochs = 35\n",
    "start = timer()\n",
    "\n",
    "history = model.fit(train, steps_per_epoch = len(train.labels) // batch_size, verbose = 1,\n",
    "                    epochs = epochs, validation_data = validation,\n",
    "                    validation_steps = len(validation.labels) // batch_size,\n",
    "                    callbacks = [es, reduce_lr, checkpoint, csv_logger])\n",
    "\n",
    "end = timer()\n",
    "print(\"Training time: %.2f s\\n\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b95836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"resnet50_transfer_t1_sagittal.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"resnet50_transfer_t1_sagittal.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('resnet50_transfer_t1_sagittal.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"resnet50_transfer_t1_sagittal.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066728c3",
   "metadata": {},
   "source": [
    "1st training:  \n",
    "\n",
    "Setup: `x = resnet_50.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(20, activation = 'relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        predictions = Dense(n_classes, activation = 'softmax')(x)`\n",
    "       \n",
    "batch size = 64 \n",
    "\n",
    "number of epochs = 35\n",
    "\n",
    "learning rate = 1e-5 with `ReduceLROnPlateau` + `EarlyStopping`\n",
    "\n",
    "training time: 414.66 s $\\approx 6$ min\n",
    "\n",
    "test accuracy: 0.6406 (overfit)\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "2nd training: \n",
    "\n",
    "Setup: `x = resnet_50.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(20, activation = 'relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        predictions = Dense(n_classes, activation = 'softmax')(x)` \n",
    "        \n",
    "froze bottom 100 layers instead\n",
    "\n",
    "batch size = 64 \n",
    "\n",
    "number of epochs = 30\n",
    "\n",
    "learning rate = 1e-5 with `ReduceLROnPlateau` + `EarlyStopping`\n",
    "\n",
    "training time: 380 s $\\approx 6$ min\n",
    "\n",
    "test accuracy: 70.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test loss + accuracy \n",
    "score = model.evaluate(test, steps = len(test.labels) // batch_size, verbose = 0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training + validation accuracy per epoch\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "n_epochs = range(len(acc))\n",
    "\n",
    "# for fancy LaTeX style plots\n",
    "from matplotlib import rc\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex = True)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(n_epochs, acc, label = 'Training accuracy')\n",
    "plt.plot(n_epochs, val_acc, label = 'Validation accuracy')\n",
    "plt.title('ResNet50: T1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc = 'best')\n",
    "#plt.savefig('ResNet50_t1_sagittal_acc.png', dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(n_epochs, loss, label = 'Training loss')\n",
    "plt.plot(n_epochs, val_loss, label = 'Validation loss')\n",
    "plt.title('ResNet50: T1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc = 'best')\n",
    "#plt.savefig('ResNet50_t1_sagittal_loss.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec917e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels\n",
    "y_true = test.classes\n",
    "\n",
    "# Get rounded predictions\n",
    "y_pred = np.argmax(model.predict(test), axis = 1) \n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "ax = sns.heatmap(cm, annot = True, fmt = 'g', cmap = 'PuBu')\n",
    "#ax = sns.heatmap(cm / np.sum(cm), annot = True, fmt = '.2%', cmap = 'PuBu')\n",
    "#for t in ax.texts: \n",
    "#    t.set_text(t.get_text().replace('%', '\\%'))\n",
    "ax.set_xlabel('\\nPredicted values')\n",
    "ax.set_ylabel('Actual values ');\n",
    "# list must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Grade 2','Grade 3', 'Grade 4'])\n",
    "ax.yaxis.set_ticklabels(['Grade 2','Grade 3', 'Grade 4'])\n",
    "plt.title('ResNet50: T1 \\n accuracy = 71.35\\%')\n",
    "#plt.savefig('ResNet50_CM_t1_sagittal.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3278a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print AUC + weighted AUC score\n",
    "weighted_auc = roc_auc_score(y_true, y_score, multi_class = 'ovr', average = 'weighted')\n",
    "auc_score = roc_auc_score(y_true, y_score, multi_class = 'ovr')\n",
    "print(f'AUC score: {auc_score:.4f}')\n",
    "print(f'Weighted AUC score: {weighted_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = 3\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true, y_score[:, i], pos_label = i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this point\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "lw = 2\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "#     label = \"macro-average ROC curve (AUC = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "#     color = \"navy\",\n",
    "#     linestyle = \":\",\n",
    "#     linewidth = 4,\n",
    "# )\n",
    "\n",
    "colors = cycle([\"orange\", \"#9A0EEA\", \"#06C2AC\"])\n",
    "plt.plot([0, 1], [0, 1], \"--\", lw = lw, color = \"#808080\")\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color = color, lw = lw,\n",
    "             label = \"G{0} (AUC = {1:0.2f})\".format(i+2, roc_auc[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multi-class ROC: ResNet50 on T1\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "#plt.savefig('Multi-class ROC - ResNet50 on T1', dpi = 300); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Save the classification report\n",
    "# clsf_report = pd.DataFrame(classification_report(y_true = y_true, y_pred = y_pred, output_dict = True)).transpose()\n",
    "# clsf_report.to_csv('Classification Report - ResNet50 on t1 sagittal.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
