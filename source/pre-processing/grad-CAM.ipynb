{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import types\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import importlib\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sys.path.append(r\"/local/data1/elech646/source/ResNet50\")\n",
    "\n",
    "# Define GradCAM object\n",
    "'''\n",
    "Grad-CAM implementation [1] as described in post available at [2].\n",
    "[1] Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra D. Grad-cam:\n",
    "    Visual explanations from deep networks via gradient-based localization.\n",
    "    InProceedings of the IEEE international conference on computer vision 2017\n",
    "    (pp. 618-626).\n",
    "[2] https://www.pyimagesearch.com/2020/03/09/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning/\n",
    "'''\n",
    "\n",
    "class gradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None,\n",
    "                use_image_prediction=True,\n",
    "                ViT=False,\n",
    "                is_3D=False,\n",
    "                debug=False):\n",
    "        '''\n",
    "        model: model to inspect\n",
    "        classIdx: index of the class to ispect\n",
    "        layerName: which layer to visualize\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "        self.debug = debug\n",
    "        self.use_image_prediction = use_image_prediction\n",
    "        self.is_ViT = ViT\n",
    "        self.is_3D = is_3D\n",
    "\n",
    "        # if the layerName is not provided, find the last conv layer in the model\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "        else:\n",
    "            if self.debug is True:\n",
    "                print('GradCAM - using layer {}'.format(self.model.get_layer(self.layerName).name))\n",
    "\n",
    "    def find_target_layer(self):\n",
    "        '''\n",
    "        Finds the last convolutional layer in the model by looping through the\n",
    "        available layers.\n",
    "        '''\n",
    "        for layer in reversed(self.model.layers):\n",
    "            # check if it is a 2D conv layer (which means that needs to have\n",
    "            # 4 dimensions [batch, width, height, channels])\n",
    "            if len(layer.output_shape) == 4:\n",
    "                # check that is a conv layer\n",
    "                if layer.name.find('conv') != -1:\n",
    "                    if self.debug is True:\n",
    "                        print('GradCAM - using layer {}'.format(layer.name))\n",
    "                    return layer.name\n",
    "\n",
    "        if self.layerName is None:\n",
    "            # if no convolutional layer have been found, rase an error since\n",
    "            # Grad-CAM can not work\n",
    "            raise ValueError('Could not find a 4D layer. Cannot apply GradCAM')\n",
    "\n",
    "    def compute_heatmap(self, image, eps=1e-6):\n",
    "        '''\n",
    "        Compute the L_grad-cam^c as defined in the original article, that is the\n",
    "        weighted sum over feature maps in the given layer with weights based on\n",
    "        the importance of the feature map on the classsification on the inspected\n",
    "        class.\n",
    "        This is done by supplying\n",
    "        1 - an input to the pre-trained model\n",
    "        2 - the output of the selected conv layer\n",
    "        3 - the final softmax activation of the model\n",
    "        '''\n",
    "        # this is a gradient model that we will use to obtain the gradients from\n",
    "        # with respect to an image to construct the heatmaps\n",
    "        gradModel = tf.keras.Model(\n",
    "                inputs=[self.model.inputs],\n",
    "                outputs=[self.model.get_layer(self.layerName).output,\n",
    "                self.model.output])\n",
    "\n",
    "        # replacing softmax with linear activation\n",
    "        gradModel.layers[-1].activation = tf.keras.activations.linear\n",
    "\n",
    "        if self.debug is True:\n",
    "            gradModel.summary()\n",
    "\n",
    "        # use the tensorflow gradient tape to store the gradients\n",
    "        with tf.GradientTape() as tape:\n",
    "            '''\n",
    "            Cast image tensor to a float-32 data type, pass the\n",
    "            image through the gradient model, and grab the loss\n",
    "            associated with the specific class index.\n",
    "            '''\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = gradModel(inputs)\n",
    "            # check if the prediction is a list (VAE)\n",
    "            if type(predictions) is list:\n",
    "                # the model is a VEA, taking only the prediction\n",
    "                predictions = predictions[4]\n",
    "            pred = tf.argmax(predictions, axis=1)\n",
    "            loss = predictions[:, self.classIdx]\n",
    "\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "        # sometimes grads becomes NoneType\n",
    "        if grads is None:\n",
    "            grads = tf.zeros_like(convOutputs)\n",
    "        '''\n",
    "        Compute the guided gradients.\n",
    "         - positive gradients if the classIdx matches the prediction (I want to\n",
    "            know which values make the probability of that class to be high)\n",
    "         - negative gradients if the classIdx != the predicted class (I want to\n",
    "            know which gradients pushed down the probability for that class)\n",
    "        '''\n",
    "        if self.use_image_prediction == True:\n",
    "            if self.classIdx == pred:\n",
    "                castConvOutputs = tf.cast(convOutputs > 0, tf.float32)\n",
    "                castGrads = tf.cast(grads > 0, tf.float32)\n",
    "            else:\n",
    "                castConvOutputs = tf.cast(convOutputs <= 0, tf.float32)\n",
    "                castGrads = tf.cast(grads <= 0, tf.float32)\n",
    "        else:\n",
    "            castConvOutputs = tf.cast(convOutputs > 0, tf.float32)\n",
    "            castGrads = tf.cast(grads > 0, tf.float32)\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "\n",
    "        # remove the batch dimension\n",
    "        convOutputs = convOutputs[0]\n",
    "        guidedGrads = guidedGrads[0]\n",
    "\n",
    "        # compute the weight value for each feature map in the conv layer based\n",
    "        # on the guided gradient\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0,1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "\n",
    "        # now that we have the activation map for the specific layer, we need\n",
    "        # to resize it to be the same as the input image\n",
    "        if self.is_ViT:\n",
    "            if self.is_3D:\n",
    "                # here we take the middle slice (don't take mean or sum since the\n",
    "                # channels are not conv filters, but the actual activation for\n",
    "                # the different images in the sequence). This is different compared\n",
    "                # to a normal conv3d, where the channels are descriptive of all\n",
    "                # the images at the same time\n",
    "                dim = int(np.sqrt(cam.shape[0]/image.shape[3]))\n",
    "                (w, h) = (image.shape[2], image.shape[1])\n",
    "                heatmap = cam.numpy().reshape((dim, dim, image.shape[3]))\n",
    "                heatmap = heatmap[:,:,heatmap.shape[-1] // 2]\n",
    "                heatmap = cv2.resize(heatmap,(w, h))\n",
    "            else:\n",
    "                dim = int(np.sqrt(cam.shape[0]))\n",
    "                (w, h) = (image.shape[2], image.shape[1])\n",
    "                heatmap = cam.numpy().reshape((dim, dim))\n",
    "                heatmap = cv2.resize(heatmap,(w, h))\n",
    "        else:\n",
    "            if self.is_3D:\n",
    "                # reshape cam to the layer input shape and then take the middle\n",
    "                # slice\n",
    "                layer_shape = self.model.get_layer(self.layerName).input_shape\n",
    "                heatmap = cam.numpy().reshape((layer_shape[1], layer_shape[2], layer_shape[3]))\n",
    "                heatmap = np.mean(heatmap, axis=-1)\n",
    "                # heatmap = heatmap[:,:,heatmap.shape[-1]//2]\n",
    "                (w, h) = (image.shape[2], image.shape[1])\n",
    "                heatmap = cv2.resize(heatmap,(w, h))\n",
    "            else:\n",
    "                (w, h) = (image.shape[2], image.shape[1])\n",
    "                heatmap = cv2.resize(cam.numpy(),(w, h))\n",
    "\n",
    "        # normalize teh heat map in [0,1] and rescale to [0, 255]\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = (numer/denom)\n",
    "        heatmap_raw = (heatmap * 255).astype('uint8')\n",
    "\n",
    "        # create heatmap based on the colormap setting\n",
    "        heatmap_rgb = cv2.applyColorMap(heatmap_raw, cv2.COLORMAP_VIRIDIS).astype('float32')\n",
    "\n",
    "        return heatmap_raw, heatmap_rgb\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_VIRIDIS):\n",
    "\n",
    "        # create heatmap based ont he colormap setting\n",
    "        heatmap = cv2.applyColorMap(heatmap, colormap).astype('float32')\n",
    "\n",
    "        if image.shape[-1] == 1:\n",
    "            # convert image from grayscale to RGB\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB).astype('float32')\n",
    "\n",
    "        output = cv2.addWeighted(image, alpha, heatmap, (1 - alpha), 0)\n",
    "\n",
    "        # return both the heatmap and the overlayed output\n",
    "        return (heatmap, output)\n",
    "\n",
    "# START ACTUAL SCRIPT - GET PATHS\n",
    "MODEL_PATH = r\"/local/data1/elech646/source/train_logs/gradCAM\"\n",
    "\n",
    "# create path for saving gradCAM\n",
    "SAVE_PATH = os.path.join(r'/local/data1/elech646/source/Plots/new_plots/gradCAM', 'resnet50_flair_sagittal_TEST')\n",
    "Path(SAVE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CREATE DATA GENERATOR (THIS SHOULD BE CHANGED BASED ON HOW YOUR GENERATOR WORKS)\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 1\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale = 1./255)\n",
    "test = test_datagen.flow_from_directory('/local/data1/elech646/Tumor_grade_classification/dataset224_RGB/dataset224_flair_sagittal/train', \n",
    "                                        classes = ['G2','G3','G4'], color_mode = 'rgb',\n",
    "                                        shuffle = False, class_mode = 'categorical', \n",
    "                                        target_size = (img_height, img_width), \n",
    "                                        batch_size = batch_size)\n",
    "nbr_test_img = len(test)\n",
    "\n",
    "# LOAD TRAINED MODEL OF CHOICE\n",
    "m_name = 'resnet50_flair_sagittal'\n",
    "model = tf.keras.models.load_model(os.path.join(MODEL_PATH, m_name, ''), compile=False)\n",
    "\n",
    "# CHECK FOR CONVOLUTIONAL LAYERS IN THE MODEL\n",
    "'''\n",
    "This heuristic needs to change based on the model architecture as well as layer names.\n",
    "Check model.summary() to get an idea of the different names.\n",
    "'''\n",
    "name_layers = []\n",
    "print('Looking for 2D conv layers...')\n",
    "for layer in model.layers:\n",
    "    # Careful here, each model has unique layer names\n",
    "    if 'conv' in layer.name:\n",
    "    # if 'conv2d' in layer.name:\n",
    "        # here no conv blocks\n",
    "        name_layers.append(layer.name)\n",
    "\n",
    "print('Found {} layers -> {}'.format(len(name_layers), name_layers))\n",
    "name_layers = name_layers[-5::]\n",
    "\n",
    "# COMPUTE GradCAM FOR EACH IMAGE IN THE DATASET AND LAYER\n",
    "'''\n",
    "Here we loop through the images in the given dataset and:\n",
    " - compute model prediction on the image\n",
    " - save image, ground truth (used later for plotting) and the prediction\n",
    " - compute the activation map for the image with respect to all the layers\n",
    "Note that one can reduce the number of layers by removing the layer names\n",
    "from the name_layers variable.\n",
    "'''\n",
    "test_images = []\n",
    "pred_logits = []\n",
    "labels = []\n",
    "heatmap_raw = []\n",
    "heatmap_rgb = []\n",
    "\n",
    "# compute activation maps for each image and each network layer\n",
    "for idx, (img, label) in enumerate(test):\n",
    "    print(f'Computing activation maps for each layer for the predicted class: {idx}/{nbr_test_img} \\r', end='')\n",
    "    # get model prediction for this image\n",
    "    img_pred_logits = model.predict(img)\n",
    "    # get model classification\n",
    "    c = np.argmax(img_pred_logits)\n",
    "    # save pred classification for mater\n",
    "    pred_logits.append(img_pred_logits)\n",
    "    # save ground truth and img\n",
    "    test_images.append(img)\n",
    "    labels.append(np.argmax(label, axis=-1)[0])\n",
    "    # for all the images, compute heatmap for all the layers\n",
    "    heatmap_raw.append([])\n",
    "    heatmap_rgb.append([])\n",
    "    for nl in name_layers:\n",
    "        cam = gradCAM(model, c, layerName = nl)\n",
    "        aus_raw, aus_rgb = cam.compute_heatmap(img)\n",
    "        heatmap_raw[idx].append(aus_raw)\n",
    "        heatmap_rgb[idx].append(aus_rgb)\n",
    "\n",
    "    if idx == nbr_test_img:\n",
    "        break\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8524315",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = []\n",
    "for roots, dirs, files in os.walk(\"/local/data1/elech646/Tumor_grade_classification/dataset224_RGB/dataset224_t1ce_sagittal/train\"):\n",
    "    for name in files:\n",
    "        if name.endswith(\".png\"):\n",
    "            filepath.append(roots + os.path.sep + name)\n",
    "            \n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE ACTIVATION MAPS (JUST FANCY PLOTTING - CAN ALWAYS BE IMPROVED)\n",
    "layers_to_print = 3 # this specifies how many layers to print from the last\n",
    "n_samples_per_image = 3\n",
    "n_images = nbr_test_img // n_samples_per_image\n",
    "fix_image = False\n",
    "save_images = True\n",
    "\n",
    "# for fancy LaTeX style plots\n",
    "import matplotlib as mpl\n",
    "mpl.rc('font',family = 'serif', serif = 'cmr10')\n",
    "plt.rcParams[\"font.serif\"] = \"cmr10\"\n",
    "plt.rcParams[\"axes.formatter.use_mathtext\"] = True\n",
    "\n",
    "for i in range(n_images):\n",
    "    print(f'Creating figure {i+1:3d}/{n_images}\\r', end='')\n",
    "\n",
    "    # create figure\n",
    "    # set different axis aspect ratios, the last axes is for the heatmap -> smaller axes\n",
    "    aus = [1 for i in range(len(range(layers_to_print)) + 1)]\n",
    "    aus[-1] = 0.1\n",
    "    gridspec = {'width_ratios': aus}\n",
    "    fig, axes = plt.subplots(nrows=n_samples_per_image, ncols=len(range(layers_to_print)) + 1, figsize=(layers_to_print*5,n_samples_per_image*2))\n",
    "    if len(axes.shape) == 1:\n",
    "        axes = np.expand_dims(axes,axis=0)\n",
    "    # fig.suptitle('Consecutive activation maps', fontsize=16)\n",
    "\n",
    "    # fill in all axes\n",
    "    for j in range(n_samples_per_image):\n",
    "        idx = i*n_samples_per_image + j\n",
    "        if idx >= nbr_test_img:\n",
    "            break\n",
    "\n",
    "        # original image\n",
    "        original_image = np.squeeze(test_images[idx][:,:,:,0])\n",
    "        if fix_image == True:\n",
    "            original_image = np.rot90(original_image, k=1)\n",
    "        axes[j, 0].imshow(original_image, cmap='gray', interpolation=None)\n",
    "        pred_str = [f'{i:0.2f}' for i in pred_logits[idx][0]]\n",
    "        if labels[idx] == np.argmax(pred_logits[idx]):\n",
    "            axes[j, 0].set_title(f'GT {labels[idx]} - Pred {pred_str}', color='g')\n",
    "        else:\n",
    "            axes[j, 0].set_title(f'GT {labels[idx]} - Pred {pred_str}', color='r')\n",
    "\n",
    "        axes[j, 0].set_xticks([])\n",
    "        axes[j, 0].set_yticks([])\n",
    "\n",
    "        # layer heatmaps\n",
    "        for idx1, idx2 in enumerate(reversed(range(layers_to_print))):\n",
    "            heat_map_image = heatmap_raw[idx][-(idx2+1)]/255\n",
    "            layer_name = name_layers[-(idx2+1)]\n",
    "            if fix_image == True:\n",
    "                heat_map_image = np.rot90(heat_map_image, k=1)\n",
    "            im = axes[j, idx1+1].imshow(heat_map_image, cmap='jet', vmin=0, vmax=1, interpolation=None)\n",
    "            axes[j, idx1+1].set_title(f'layer {layer_name}')\n",
    "            axes[j, idx1+1].set_xticks([])\n",
    "            axes[j, idx1+1].set_yticks([])\n",
    "\n",
    "        # add colorbar as an extra axis\n",
    "        aspect = 20\n",
    "        pad_fraction = 0.5\n",
    "\n",
    "        divider = make_axes_locatable(axes[j,-1])\n",
    "        width = axes_size.AxesY(axes[j,-1], aspect=1./aspect)\n",
    "        pad = axes_size.Fraction(pad_fraction, width)\n",
    "        cax = divider.append_axes(\"right\", size=width, pad=pad)\n",
    "        plt.colorbar(im, cax=cax)\n",
    "\n",
    "    if save_images:\n",
    "        fig.savefig(os.path.join(SAVE_PATH, 'activationMap_forConsecutiveLayers_%03d.png' % i), bbox_inches='tight', dpi = 400)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
